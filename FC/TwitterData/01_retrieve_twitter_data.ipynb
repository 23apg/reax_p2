{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from pprint import pprint\n",
    "import pymongo\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "from twtkey import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)\n",
    "\n",
    "\n",
    "#connection with Mongo\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "db = client.project_reax\n",
    "db_cities_full = db.cities_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def nlp_me(comment):\n",
    "   #feed me text strings, I dance with spacy\n",
    "   nlp_key = []\n",
    "   nlp_value = []\n",
    "   doc = nlp(comment)\n",
    "   if not doc.ents:\n",
    "       nlp_key.append(\"no key\")\n",
    "       nlp_value.append(\"no entry\")\n",
    "   else:\n",
    "       for ent in doc.ents:\n",
    "           nlp_key.append(ent.text)\n",
    "           nlp_value.append(ent.label_)\n",
    "\n",
    "   return nlp_key, nlp_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_city_ids = []\n",
    "results = db_cities_full.find()\n",
    "for result in results:\n",
    "    try:\n",
    "        list_city_ids.append(result[\"woeids\"][0][\"Id\"])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Removedups(duplicate): \n",
    "    final_list = [] \n",
    "    for num in duplicate: \n",
    "        if num not in final_list: \n",
    "            final_list.append(num) \n",
    "    return final_list \n",
    "\n",
    "list_city_ids = Removedups(list_city_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Twitter Trends for each City\n",
    "\n",
    "twitter_trends = []\n",
    "\n",
    "for cityid in list_city_ids:\n",
    "    try:\n",
    "        trends1 = api.trends_place(cityid)\n",
    "        twitter_trends.append(trends1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trend in twitter_trends:\n",
    "    for trendelement in trend:\n",
    "        db.twitter_trends.insert_one(trendelement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting top trends in US (country overall)\n",
    "#trends1 = api.trends_place(23424977)\n",
    "db.twitter_trends.insert_one(trends1[0])\n",
    "#pprint(trends1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "     {\"$lookup\": {\"from\": \"city_full_lite\", \"localField\": \"locations.woeid\", \"foreignField\": \"Id\", \"as\": \"coordinates\"}}]\n",
    "     \n",
    "db.twitter_trends_full.insert_many(db.twitter_trends.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_woeid = 23424977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for trend in db.twitter_trends_full.find({\"locations.woeid\": trend_woeid})[0][\"trends\"]:\n",
    "    i = i+1\n",
    "    if (i==6):\n",
    "        break\n",
    "    if (i<4):\n",
    "        continue\n",
    "        \n",
    "    trend_name = trend[\"name\"]\n",
    "\n",
    "    for location in db.twitter_trends_full.find():\n",
    "    \n",
    "        try:\n",
    "            lat = location[\"coordinates\"][0][\"latitude\"]\n",
    "            lng = location[\"coordinates\"][0][\"longitude\"]\n",
    "            city = location[\"coordinates\"][0][\"city\"]\n",
    "            state = location[\"coordinates\"][0][\"state\"]\n",
    "            woeid = location[\"coordinates\"][0][\"Id\"]\n",
    "    \n",
    "            geocode = str(lat) + \",\" + str(lng) + \",50mi\"\n",
    "            public_tweets = api.search(trend_name, tweet_mode=\"extended\", count=10, result_type=\"recent\", geocode=geocode)\n",
    "    \n",
    "            db.twitter_trends_full.update_one(\n",
    "            {\"locations.woeid\": trend_woeid, 'trends.name': trend_name},\n",
    "            { \"$push\": \n",
    "               {\"trends.$.public_tweets\": {\n",
    "                   \"woeid\": woeid,\n",
    "                   \"latitude\": lat,\n",
    "                   \"longitude\": lng,\n",
    "                   \"state\": state,\n",
    "                   \"city\": city,\n",
    "                   \"tweets\": public_tweets\n",
    "               }}\n",
    "            }\n",
    "            )\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Vader Analysis on each tweet\n",
    "\n",
    "i = 0\n",
    "\n",
    "for trend in db.twitter_trends_full.find({\"locations.woeid\": trend_woeid})[0][\"trends\"]:\n",
    "    i = i+1\n",
    "    if (i==6):\n",
    "        break\n",
    "        \n",
    "    trend_name = trend[\"name\"]\n",
    "    nlp_key_list=[]\n",
    "    nlp_value_list=[]\n",
    "        \n",
    "    for tweet_location in trend[\"public_tweets\"]:\n",
    "        woeid = tweet_location[\"woeid\"]\n",
    "        \n",
    "        vader_scores=[]\n",
    "        \n",
    "        for tweet in tweet_location['tweets']['statuses']:\n",
    "            try:\n",
    "                text = tweet[\"retweeted_status\"][\"full_text\"]\n",
    "                \n",
    "            except:\n",
    "                text = tweet[\"full_text\"]\n",
    "                \n",
    "            score = analyzer.polarity_scores(text)\n",
    "            nlp_key, nlp_value = nlp_me(text)\n",
    "            #if score[\"neu\"] != 1:\n",
    "            vader_scores.append(score[\"compound\"])\n",
    "            nlp_key_list.append(nlp_key)\n",
    "            nlp_value_list.append(nlp_value)\n",
    "        #print (str(trend_woeid) + \",\" + str(trend_name) +\",\" +str(woeid))\n",
    "        \n",
    "        \n",
    "        db.twitter_trends_full.update_one(\n",
    "            {\"locations.woeid\": trend_woeid, \"trends.name\": trend_name, \"trends.public_tweets.woeid\": woeid},\n",
    "            { \"$set\":\n",
    "                {\"trends.$[trend].public_tweets.$[elem].vader_scores\": vader_scores}\n",
    "            }\n",
    "            ,array_filters=[{\"trend.name\": trend_name},{\"elem.woeid\": woeid }]\n",
    "            )\n",
    "        \n",
    "    db.twitter_trends_full.update_one(\n",
    "            {\"locations.woeid\": trend_woeid, \"trends.name\": trend_name, \"trends.public_tweets.woeid\": woeid},\n",
    "            { \"$set\":\n",
    "                {\"trends.$[trend].spacy_npl\": {\"nlp_key\": nlp_key_list, \"nlp_value\": nlp_value_list}}\n",
    "            }\n",
    "            ,array_filters=[{\"trend.name\": trend_name}]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
