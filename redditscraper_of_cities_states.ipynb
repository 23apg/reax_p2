{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APG\\Anaconda3\\envs\\AngelosAwesomeEnvironment\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\APG\\Anaconda3\\envs\\AngelosAwesomeEnvironment\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\APG\\Anaconda3\\envs\\AngelosAwesomeEnvironment\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\APG\\Anaconda3\\envs\\AngelosAwesomeEnvironment\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from time import sleep\n",
    "import pymongo\n",
    "import numpy as np\n",
    "import spacy\n",
    "import tweepy\n",
    "from pprint import pprint\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_me(comment):\n",
    "    #feed me text strings, I dance with spacy\n",
    "    nlp_key = []\n",
    "    nlp_value = []\n",
    "    doc = nlp(comment)\n",
    "    if not doc.ents:\n",
    "        nlp_key.append(\"no key\")\n",
    "        nlp_value.append(\"no entry\")\n",
    "    else:\n",
    "        for ent in doc.ents:\n",
    "            nlp_key.append(ent.text)\n",
    "            nlp_value.append(ent.label_)\n",
    "            \n",
    "    return nlp_key, nlp_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^start grab^^^^^\n",
      "grabbing stuff:NYC\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Seattle\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Chicago\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:LosAngeles\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Portland\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Boston\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Austin\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:SanFrancisco\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Atlanta\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Philadelphia\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Denver\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Melbourne\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Columbus\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Dallas\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Baltimore\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:StLouis\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:BayArea\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:washingtondc\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:twincitiessocial\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:sandiego\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:pittsburgh\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:houston\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Anchorage\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:phoenix\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Sacramento\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:orlando\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:louisville\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:neworleans\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:nashville\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Miami\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:vegas\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:SaltLakeCity\n",
      "mmmmmmmmmmmmmmmm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def reddit():\n",
    "\n",
    "    reddit = praw.Reddit(client_id='', \\\n",
    "                     client_secret='', \\\n",
    "                     user_agent='nw_project2_getcities', \\\n",
    "                     username='', \\\n",
    "                     password='')\n",
    "    return reddit\n",
    "\n",
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "\n",
    "\n",
    "def comment_data_gen(comment):\n",
    "    \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    results = analyzer.polarity_scores(comment.body)\n",
    "    \n",
    "    testimonial = TextBlob(comment.body)\n",
    "    blob = dict(sentimentblobpolar = testimonial.sentiment.polarity,\n",
    "            sentimentsubjectivity = testimonial.sentiment.subjectivity)\n",
    "    \n",
    "    stamp = get_date(comment.created_utc)\n",
    "\n",
    "    return dict(\n",
    "        text = comment.body,\n",
    "        length = len(comment.body),\n",
    "        timestamp = stamp,\n",
    "        subreddit = comment.subreddit_name_prefixed,\n",
    "        karma = dict(\n",
    "            compound = comment.score,\n",
    "            ups = comment.ups,\n",
    "            downs = comment.downs\n",
    "        ),\n",
    "        vader = results,\n",
    "        blob = blob\n",
    "\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "city_subreddits = ['NYC', 'Seattle', 'Chicago', 'LosAngeles', 'Portland', 'Boston', 'Austin', \n",
    "'SanFrancisco', 'Atlanta', 'Philadelphia', 'Denver',  \"Columbus\",\n",
    "'Dallas', 'Baltimore', 'StLouis', 'BayArea', 'washingtondc', \n",
    "'twincitiessocial', 'sandiego', 'pittsburgh', 'houston', \"Anchorage\", \"phoenix\", 'Sacramento', \"orlando\",\n",
    " \"nashville\", \"Miami\",  \"SaltLakeCity\"]\n",
    "\n",
    "r = reddit()\n",
    "\n",
    "city_sent = []\n",
    "\n",
    "for sub in city_subreddits:\n",
    "\n",
    "    subs = r.subreddit(sub)\n",
    "\n",
    "    print(\"^^^^start grab^^^^^\")\n",
    "    print(\"grabbing stuff:\" + sub)\n",
    "    print(\"mmmmmmmmmmmmmmmm\")\n",
    "    \n",
    "\n",
    "\n",
    "    #append to empty holders\n",
    "    for submission in subs.top(\"day\", limit=25):\n",
    "       \n",
    "        title = submission.title\n",
    "        url = submission.url\n",
    "        comments_number = submission.num_comments\n",
    "        subred = submission.subreddit\n",
    "#         print(subred)\n",
    "\n",
    "        for x in range(1):\n",
    "            nlp_kv = nlp_me(title)\n",
    "            key, value = nlp_kv\n",
    "            city_feels = dict(datetime = dt.datetime.now().strftime('%Y-%m-%d'),\n",
    "                              title = title,\n",
    "                              location = str(subred),\n",
    "                              url = url,\n",
    "                              keys = key,\n",
    "                              values = value,\n",
    "                              comments_number = comments_number,\n",
    "                              comment_dict = [])\n",
    "            \n",
    "        \n",
    "            for comment in submission.comments:\n",
    "                try:\n",
    "                    get_com_data = comment_data_gen(comment)\n",
    "                    city_feels['comment_dict'].append(get_com_data)\n",
    "\n",
    "                    \n",
    "                except AttributeError:\n",
    "                    city_feels[\"comment_dict\"].append(\"sNaN\")\n",
    "            \n",
    "        city_sent.append(city_feels)\n",
    "        \n",
    "\n",
    "        \n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['Alabama', \n",
    "'Alaska', \n",
    "'Arizona', \n",
    "'Arkansas',\n",
    "'California',\n",
    "'Colorado', \n",
    "'Connecticut',\n",
    "'Delaware', \n",
    "'Florida', \n",
    "'Georgia',\n",
    "'Hawaii', \n",
    "'Idaho', \n",
    "'Illinois',\n",
    "'Indiana', \n",
    "'Iowa', \n",
    "'Kansas', \n",
    "'Kentucky', \n",
    "'Louisiana', \n",
    "'Maine', \n",
    "'Maryland', \n",
    "'Massachusetts', \n",
    "'Michigan', \n",
    "'Minnesota', \n",
    "'Mississippi', \n",
    "'Missouri', \n",
    "'Montana',\n",
    "'Nebraska', \n",
    "'Nevada', \n",
    "'NewHampshire', \n",
    "'NewJersey', \n",
    "'NewMexico', \n",
    "'NewYork', \n",
    "'NorthCarolina', \n",
    "'NorthDakota', \n",
    "'Ohio', \n",
    "'Oklahoma', \n",
    "'Oregon', \n",
    "'Pennsylvania', \n",
    "'RhodeIsland', \n",
    "'SouthCarolina', \n",
    "'SouthDakota',\n",
    "'Tennessee', \n",
    "'Texas', \n",
    "'Utah', \n",
    "'Vermont', \n",
    "'Virginia', \n",
    "'Washington', \n",
    "'WestVirginia', \n",
    "'Wisconsin', \n",
    "'Wyoming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Alabama\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Alaska\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Arizona\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Arkansas\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:California\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Colorado\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Connecticut\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Delaware\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Florida\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Georgia\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Hawaii\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Idaho\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Illinois\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Indiana\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Iowa\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Kansas\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Kentucky\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Louisiana\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Maine\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Maryland\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Massachusetts\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Michigan\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Minnesota\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Mississippi\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Missouri\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Montana\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Nebraska\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Nevada\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:NewHampshire\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:NewJersey\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:NewMexico\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:NewYork\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:NorthCarolina\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:NorthDakota\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Ohio\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Oklahoma\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Oregon\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Pennsylvania\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:RhodeIsland\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:SouthCarolina\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:SouthDakota\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Tennessee\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Texas\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Utah\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Vermont\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Virginia\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Washington\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:WestVirginia\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Wisconsin\n",
      "mmmmmmmmmmmmmmmm\n",
      "^^^^start grab^^^^^\n",
      "grabbing stuff:Wyoming\n",
      "mmmmmmmmmmmmmmmm\n"
     ]
    }
   ],
   "source": [
    "r = reddit()\n",
    "\n",
    "state_sent = []\n",
    "\n",
    "for sub in states:\n",
    "\n",
    "    subs = r.subreddit(sub)\n",
    "\n",
    "    print(\"^^^^start grab^^^^^\")\n",
    "    print(\"grabbing stuff:\" + sub)\n",
    "    print(\"mmmmmmmmmmmmmmmm\")\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    #append to empty holders\n",
    "    for submission in subs.top(\"day\", limit=25):\n",
    "       \n",
    "        title = submission.title\n",
    "        url = submission.url\n",
    "        comments_number = submission.num_comments\n",
    "        subred = submission.subreddit\n",
    "\n",
    "\n",
    "        for x in range(1):\n",
    "            nlp_kv = nlp_me(title)\n",
    "            key, value = nlp_kv\n",
    "            state_feels = dict(datetime = dt.datetime.now().strftime('%Y-%m-%d'),\n",
    "                              title = title,  \n",
    "                              location = str(subred),\n",
    "                              url = url,\n",
    "                              keys = key,\n",
    "                              values = value,\n",
    "                              comments_number = comments_number,\n",
    "                              comment_dict = [])\n",
    "        \n",
    "            for comment in submission.comments:\n",
    "                try:\n",
    "                    get_com_data = comment_data_gen(comment)\n",
    "                    state_feels['comment_dict'].append(get_com_data)\n",
    "\n",
    "                    \n",
    "                except AttributeError:\n",
    "                    state_feels.append(\"sNaN\")\n",
    "            \n",
    "        state_sent.append(state_feels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comment_dict': [{'blob': {'sentimentblobpolar': -0.35,\n",
      "                            'sentimentsubjectivity': 0.6000000000000001},\n",
      "                   'karma': {'compound': 10, 'downs': 0, 'ups': 10},\n",
      "                   'length': 25,\n",
      "                   'subreddit': 'r/Alabama',\n",
      "                   'text': 'Well this not good news, ',\n",
      "                   'timestamp': datetime.datetime(2018, 11, 23, 22, 29, 29),\n",
      "                   'vader': {'compound': -0.0788,\n",
      "                             'neg': 0.321,\n",
      "                             'neu': 0.4,\n",
      "                             'pos': 0.28}},\n",
      "                  {'blob': {'sentimentblobpolar': -0.095,\n",
      "                            'sentimentsubjectivity': 0.46},\n",
      "                   'karma': {'compound': 7, 'downs': 0, 'ups': 7},\n",
      "                   'length': 36,\n",
      "                   'subreddit': 'r/Alabama',\n",
      "                   'text': 'This whole deal seems very confusing',\n",
      "                   'timestamp': datetime.datetime(2018, 11, 23, 22, 35, 35),\n",
      "                   'vader': {'compound': -0.2944,\n",
      "                             'neg': 0.305,\n",
      "                             'neu': 0.695,\n",
      "                             'pos': 0.0}},\n",
      "                  {'blob': {'sentimentblobpolar': -0.1,\n",
      "                            'sentimentsubjectivity': 0.2},\n",
      "                   'karma': {'compound': 2, 'downs': 0, 'ups': 2},\n",
      "                   'length': 146,\n",
      "                   'subreddit': 'r/Alabama',\n",
      "                   'text': 'Am I remembering the initial report that lots of '\n",
      "                           'people pulled guns when the shooting started? '\n",
      "                           'Maybe the dead guy decided he wanted to be a '\n",
      "                           'hero. ',\n",
      "                   'timestamp': datetime.datetime(2018, 11, 24, 7, 59, 29),\n",
      "                   'vader': {'compound': -0.1779,\n",
      "                             'neg': 0.139,\n",
      "                             'neu': 0.744,\n",
      "                             'pos': 0.117}}],\n",
      " 'comments_number': 14,\n",
      " 'datetime': '2018-11-24',\n",
      " 'keys': ['Galleria'],\n",
      " 'location': 'Alabama',\n",
      " 'title': 'Hoover Police: New evidence shows Galleria shooting suspect likely '\n",
      "          'remains at-large',\n",
      " 'url': 'https://www.wvtm13.com/article/hoover-police-new-evidence-shows-galleria-shooting-suspect-likely-remains-at-large/25293992',\n",
      " 'values': ['PERSON']}\n"
     ]
    }
   ],
   "source": [
    "pprint(state_sent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.project_reax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in state_sent:\n",
    "    db.reddit_state.insert_one(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in city_sent:\n",
    "    db.reddit_city.insert_one(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Manhattan Bridge']\n",
      "['New Yorkers', 'U.S.', 'Iraq', 'Heroes', '1991']\n",
      "['Times Square']\n",
      "['Brooklyn Bridge']\n",
      "['120', 'mm']\n",
      "['up to 82', '180', 'Penn']\n",
      "['Brooklyn Bridge']\n",
      "['no key']\n",
      "['no key']\n",
      "['Oscar Healthcare']\n",
      "['one', 'the summer']\n",
      "['HUD Tallied Numerous Violations', 'New York City Public Housing']\n",
      "['Uber']\n",
      "['Udon West', '150', '46th', '15']\n",
      "['about 45 minutes ago']\n",
      "['no key']\n",
      "['Bennet Field']\n",
      "['Joanna Ebenstein', 'Morbid Anatomy Museum']\n",
      "['no key']\n",
      "['Manhattan']\n",
      "['no key']\n",
      "['Gage & Tollner']\n",
      "['LES']\n",
      "['one']\n",
      "['Winter']\n",
      "['Seattle']\n",
      "['the Space Needle', 'bright tonight']\n",
      "['First', 'Seattle']\n",
      "['6 years', 'Seattle', '40 seconds']\n",
      "['Matter', 'Black Friday', 'Seattle']\n",
      "['no key']\n",
      "['TIL',\n",
      " '2004',\n",
      " '50 First Dates',\n",
      " 'Seattle',\n",
      " 'Adam Sandler',\n",
      " 'Hawaii',\n",
      " '/r/TodayILearned']\n",
      "['no key']\n",
      "['Meridian Health Center']\n",
      "['Two']\n",
      "['tonight']\n",
      "['no key']\n",
      "['no key']\n",
      "['E30 M3']\n",
      "['the Neon House']\n",
      "['no key']\n",
      "['last month']\n",
      "['Skyline', 'Lake Michigan']\n",
      "['Harold Washington Library']\n",
      "['World',\n",
      " 'Fastest Animal',\n",
      " 'NOVA - Highlights Chicago as Environment for Peregrines']\n",
      "['Winter', '10 AM', '4 AM', 'Monday']\n",
      "['Mike Ditka', 'this week']\n",
      "['Chicagoans']\n",
      "['no key']\n",
      "['840 S. Michigan']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['Tips', 'winter']\n",
      "['no key']\n",
      "['no key']\n",
      "['Hollywood']\n",
      "['CA DMV', 'Pasadena DMV', 'Saturdays', 'today']\n",
      "['L.A.']\n",
      "['Saturday']\n",
      "['Jerry Brown', 'CA', 'Roderick Wright']\n",
      "['South Bay', 'two', 'Los Angeles Times']\n",
      "['LAPD Cracks Down']\n",
      "['Clifton’s - worth']\n",
      "['LA', 'Din Tai Fung']\n",
      "['no key']\n",
      "['no key']\n",
      "['Long Beach']\n",
      "['134']\n",
      "['Los Angeles', 'LA']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['Ito En']\n",
      "['Dana Point']\n",
      "['ACH', 'Noon today', '30']\n",
      "['140']\n",
      "['LA', '2 months']\n",
      "['60s']\n",
      "['no key']\n",
      "['Christmas season']\n",
      "['Wal Mart']\n",
      "['Portland Outdoor Store', 'Neon Sign']\n",
      "['NW', 'this morning']\n",
      "['the Tram']\n",
      "['Portland']\n",
      "['Netflix', '3', 'UK', 'Portland']\n",
      "['the Rain | Forest Park']\n",
      "['McMenamins']\n",
      "['Powell Butte']\n",
      "['Kerns Neighborhood']\n",
      "['no key']\n",
      "['Nearly 700,000',\n",
      " 'Scooter Rides',\n",
      " 'the City’s Pilot Program',\n",
      " 'Scooters',\n",
      " 'over 800,000']\n",
      "['no key']\n",
      "['Bonneville Power']\n",
      "['The Library Foundation', 'Season of Sharing 2018']\n",
      "['the Hawthorn Bridge']\n",
      "['no key']\n",
      "['West Hills']\n",
      "['no key']\n",
      "['no key']\n",
      "['Lost Backpack']\n",
      "['no key']\n",
      "['Chill', 'Portland']\n",
      "['Trump',\n",
      " '321 acres',\n",
      " 'the Mashpee-Wampanoag',\n",
      " 'the United States',\n",
      " 'Resistbot']\n",
      "['today']\n",
      "['Shaleen Title:']\n",
      "['CBT']\n",
      "['1870']\n",
      "['Jen Royle', 'Italian']\n",
      "['no key']\n",
      "['Marcy Ostberg', \"Tackle Boston's\"]\n",
      "['Park Street', 'a rainy night', 'OC']\n",
      "['Marijuana']\n",
      "['Natick']\n",
      "['no key']\n",
      "['AND']\n",
      "['Logan', 'Sunday', 'morning', 'Thanksgiving']\n",
      "['no key']\n",
      "['Austin', 'a couple weeks ago', 'today']\n",
      "['Austin', 'Rundberg', 'Northgate', 'Austin']\n",
      "['no key']\n",
      "['Austin', '50']\n",
      "['no key']\n",
      "['N. Lamar', 'November 4, 1961']\n",
      "['Crazy']\n",
      "['43rd', 'Hyde Park', 'Austin', '20+ years']\n",
      "['no key']\n",
      "['Matt']\n",
      "['360']\n",
      "['Two']\n",
      "['Christmas Day', 'Orphan', 'Christmas']\n",
      "['Nixon']\n",
      "['Austin']\n",
      "['no key']\n",
      "['Hyde Park']\n",
      "['Dungeons & Dragons']\n",
      "['Picnic Areas', 'BBQ']\n",
      "['no key']\n",
      "['last night']\n",
      "['first']\n",
      "['no key']\n",
      "['no key']\n",
      "['San Francisco', '1941']\n",
      "['today', 'City', 'the Bay']\n",
      "['Embarcadero']\n",
      "['Thanksgiving', 'morning']\n",
      "['no key']\n",
      "['SF', '2 weeks ago']\n",
      "['SF', '74.4%']\n",
      "['yesterday']\n",
      "['no key']\n",
      "['no key']\n",
      "['The Etsy Fair']\n",
      "['last week']\n",
      "['mid-20s']\n",
      "['no key']\n",
      "['today']\n",
      "['no key']\n",
      "['no key']\n",
      "['Clay', 'tonight']\n",
      "['no key']\n",
      "['Man Shot', 'Booting Company', 'Employee', 'Grandfather', 'Being Shot']\n",
      "['Weeks', 'Georgia', 'Over 1.6 million', '2010']\n",
      "['Monday']\n",
      "['FYI', 'Georgia Power Marketplace', 'this four-day weekend', 'Georgia Power']\n",
      "['Beltline']\n",
      "['Atlanta']\n",
      "['Illegal Food at Wild', 'Korean']\n",
      "['Avondale Towne Cinema', '12/15']\n",
      "['/r/Atlanta Random Daily Discussion - November 24, 2018']\n",
      "['no key']\n",
      "['Kurt Vile', 'Variety', 'Dec 3rd']\n",
      "['Gay']\n",
      "['no key']\n",
      "['Atlanta', 'today', 'San Francisco']\n",
      "['Atlanta', 'Alive', 'next year']\n",
      "['800']\n",
      "['no key']\n",
      "['2', 'tonight', 'the Tabernacle', '30']\n",
      "['no key']\n",
      "['ATL', 'Fill You Up']\n",
      "['no key']\n",
      "['Stacey', 'Georgia']\n",
      "['2', 'Tash Sultana']\n",
      "['two']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['Philadelphia']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['Cheesesteak']\n",
      "['Texas', 'Friday']\n",
      "['Christmas']\n",
      "['PSA', 'Mainstay Brewing Co', 'Columbus Blvd']\n",
      "['1980', 'Philadelphia', 'Germantown & CC']\n",
      "['30']\n",
      "['The Conshy Ballet']\n",
      "['no key']\n",
      "['no key']\n",
      "['Walnut Hill']\n",
      "['the winter']\n",
      "['OC']\n",
      "['no key']\n",
      "['no key']\n",
      "['Tips for Expired Inspection']\n",
      "['last night', 'Denver']\n",
      "['no key']\n",
      "['the moon.', 'Full Moon last night', 'Lookout Mountain', 'Denver']\n",
      "['1600 w. 15th', 'Lower Downtown Denver', '1880']\n",
      "['10-hr']\n",
      "['Colorado']\n",
      "['Colorado']\n",
      "['no key']\n",
      "['Weekly Question and Answer Thread',\n",
      " '11/24',\n",
      " 'Neighborhood',\n",
      " 'Where Can I Find _']\n",
      "['Marijuana Legalization Forcing Some Drug-Sniffing-Dogs Into Retirement']\n",
      "['no key']\n",
      "['Denver']\n",
      "['Earwax Removal', 'Denver']\n",
      "['Denver']\n",
      "['Davis Hanson Waite', '1825-1901']\n",
      "['no key']\n",
      "['1 month anniversary', 'Colorado']\n",
      "['PSA']\n",
      "['Snooze A.M. Eatery', '🤔']\n",
      "['Indian']\n",
      "['Moody Melbourne', 'dusk', 'last year']\n",
      "['Flight Tracker']\n",
      "['night']\n",
      "['Elon', '@lushsux', 'today']\n",
      "['Hinkler', 'Glen Waverley']\n",
      "['no key']\n",
      "['Antonov', 'Melbourne']\n",
      "['no key']\n",
      "['Riot', 'Rye']\n",
      "['Melbourne']\n",
      "['Bachelor of Business']\n",
      "['no key']\n",
      "['Jaadu']\n",
      "['Laneway Festival']\n",
      "['no key']\n",
      "['Derrimutt', 'Bikies', 'BS']\n",
      "['Sunday 25/11/2018']\n",
      "['California', 'Columbus', 'roughly 143,000 acres', 'over 150,000 acres']\n",
      "['Kohl', 'Grove City', 'Late Black Friday Night']\n",
      "['no key']\n",
      "['the Zoo Lights']\n",
      "['Italian Village', 'Franklinton']\n",
      "['Bernie']\n",
      "['Columbus']\n",
      "['Laptop Battery Recycling']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['30th']\n",
      "['Arbor Hills']\n",
      "['Arlington']\n",
      "['Animal Rescues']\n",
      "['Fun Free Things', 'Dallas', 'Dallas']\n",
      "['House', 'Greenspring Avenue']\n",
      "['Slovenia']\n",
      "['no key']\n",
      "['Sarasota']\n",
      "['Baltimore County']\n",
      "['3', 'Dec. 5', '1:00 to 3:00 p.m.', 'Homewood']\n",
      "['no key']\n",
      "['Station North Flea Market', '12-4']\n",
      "['no key']\n",
      "['Linebacker Diondre Wallace', 'emotional’', 'Towson']\n",
      "['Baltimore City']\n",
      "['tonight']\n",
      "['no key']\n",
      "['St. Louis']\n",
      "['St. Louis']\n",
      "['STL City Flag Recommendations']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['St. Louis']\n",
      "['no key']\n",
      "['St. Louis City']\n",
      "['no key']\n",
      "['today']\n",
      "['no key']\n",
      "['Cape/AFG']\n",
      "['no key']\n",
      "['One', 'Bart']\n",
      "['Petaluma']\n",
      "['the Bay Area', 'Yosemite National Park']\n",
      "['Toyota', 'Camp Fire']\n",
      "['Palo Alto']\n",
      "['Arson', '1', '9', 'East Bay']\n",
      "['Burlingame', 'This Year']\n",
      "['the Bay Area']\n",
      "['Mt. Diablo']\n",
      "['no key']\n",
      "['SF']\n",
      "['no key']\n",
      "['SF']\n",
      "['Bay Area Taxes']\n",
      "['no key']\n",
      "['no key']\n",
      "['Richmond']\n",
      "['Overnight']\n",
      "['100', '10-15 minutes', 'English', 'ASAP']\n",
      "['no key']\n",
      "['National Cathedral', 'Tuesday', 'night']\n",
      "['today (Nov. 24', '11', 'Union Market - free']\n",
      "['no key']\n",
      "['32 year old']\n",
      "['day']\n",
      "['Cheverly']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['Point Loma']\n",
      "['no key']\n",
      "['Anza', 'Fonts', 'One', 'San Diego County']\n",
      "['no key']\n",
      "['San Diego']\n",
      "['two', 'Goldn Bloom Dispensary', 'FBI', 'Owner', 'FBI', '2014']\n",
      "['Torrey Pines', 'Subaru']\n",
      "['no key']\n",
      "['Cheesecake Factory', 'Fashion Valley']\n",
      "['Black Mountain Pano']\n",
      "['the Coronado Bridge']\n",
      "['MTB']\n",
      "['no key']\n",
      "['Orange County', '9 am']\n",
      "['no key']\n",
      "['a little over a year ago']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['San Diego']\n",
      "['no key']\n",
      "['Benedum Center']\n",
      "['Pittsburgh']\n",
      "['Indie Rock']\n",
      "['Pittsburgh', 'Catholic', 'Anglican', 'Baptist', 'the 2nd year', '1,000,000']\n",
      "['the Pittsburgh Holiday Parade']\n",
      "['Mount Washington']\n",
      "['Tots']\n",
      "['Italian']\n",
      "['no key']\n",
      "['Japanese']\n",
      "['no key']\n",
      "['Rahal', 'Wexford']\n",
      "['UGA']\n",
      "['no key']\n",
      "['Jenni', 'Noodle House', 'Heights', 'TF', 'Sermi']\n",
      "['Houston', 'tonight', 'Moondog']\n",
      "['5', '1 day']\n",
      "['Virginia:::got', 'Houston']\n",
      "['45']\n",
      "['Houston']\n",
      "['no key']\n",
      "['Saw', 'San Felipe de Austin State', 'Historic Site', 'San Felipe', 'TX']\n",
      "['the Houston area']\n",
      "['RIP Bob McNair', 'Times Square']\n",
      "['no key']\n",
      "['no key']\n",
      "['Rice Military', 'Hyde Park']\n",
      "['Dallas', 'Houston', 'Austin & Fort Worth']\n",
      "['no key']\n",
      "['no key']\n",
      "['Christmas']\n",
      "['no key']\n",
      "['2']\n",
      "['Sprint', 'Houston', 'Cypress']\n",
      "['no key']\n",
      "['next weekend']\n",
      "['Nine', 'Arizona']\n",
      "['today', '170', 'Christmas']\n",
      "['Amazon', '$5 million', 'Phoenix']\n",
      "['Boca Juniors VS River Plate']\n",
      "['/r', 'Phoenix', 'weekend', 'November 24, 2018']\n",
      "['no key']\n",
      "['Scottsdale/Temple']\n",
      "['no key']\n",
      "['Central Phoenix']\n",
      "['Scottsdale']\n",
      "['no key']\n",
      "['no key']\n",
      "['Harrowing Before & After Shots of Paradise']\n",
      "['Thanksgiving - 1:00 PM - Front Street', 'Broadway']\n",
      "['At least 1', 'Interstate 5']\n",
      "['no key']\n",
      "['Lindsey Stirling', 'tonight']\n",
      "['no key']\n",
      "['tomorrow']\n",
      "['tomorrow']\n",
      "['no key']\n",
      "['Sacramento']\n",
      "['the SF/Bay Area']\n",
      "['Stevante Clark', 'Stephon Clark', 'Sacramento']\n",
      "['RUN', 'WINTER PARK']\n",
      "['Foster', 'Violet']\n",
      "['Saturday']\n",
      "['Male Adult', '21yo', 'Gymnastics']\n",
      "['no key']\n",
      "['Organic']\n",
      "['UCF', '560']\n",
      "['Orlando']\n",
      "['Central Florida', 'Small Business', 'Saturday']\n",
      "['no key']\n",
      "['no key']\n",
      "['Orlando', 'Orlando']\n",
      "['Paella']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['3 days', 'Orlando']\n",
      "['no key']\n",
      "['no key']\n",
      "['no key']\n",
      "['Backpacking', 'Louisville']\n",
      "['no key']\n",
      "['One']\n",
      "['Hibiki Harmony', '2018']\n",
      "['no key']\n",
      "['Montana']\n",
      "['U of L', 'Microsoft', '10']\n",
      "['Louisville Deserve', 'Big 5 Team']\n",
      "['today']\n",
      "['tonight']\n",
      "['no key']\n",
      "['Great Blue Heron', 'Today', 'Bayou St. John']\n",
      "['Bank Fishing Louisiana New Orleans', 'Shell Beach']\n",
      "['Tailor']\n",
      "['NOLA']\n",
      "['New Orleans']\n",
      "['NIN']\n",
      "['no key']\n",
      "['5']\n",
      "['Nashville']\n",
      "['ML Rose', '8th', 'tonight']\n",
      "['Nashville']\n",
      "['Tomorrow', 'the Shoppes', 'Saturday Nov 24th']\n",
      "['no key']\n",
      "['Nashville']\n",
      "['Chuck Liddell', 'Tito Ortiz']\n",
      "['Stolen Nintendo Switch']\n",
      "['Miami']\n",
      "['winter days']\n",
      "['South Beach', 'Miami']\n",
      "['Downtown Miami Burdines', '1950']\n",
      "['morning', 'Miami']\n",
      "['no key']\n",
      "['US']\n",
      "['El Farito', 'one', 'Miami', 'Miami', '“Lights Out', 'iTunes']\n",
      "['no key']\n",
      "['F-15s']\n",
      "['Miami']\n",
      "['no key']\n",
      "['Miami']\n",
      "['Miami']\n",
      "['the Budget BUDGET Suites', 'S LV Blvd']\n",
      "['Red Rock']\n",
      "['25', 'Ways to Celebrate Christmas', 'Las Vegas']\n",
      "['Christmas']\n",
      "['Chamberlain College']\n",
      "['no key']\n",
      "['Las Vegas']\n",
      "['no key']\n",
      "['tonight', '11/24', 'VGK', 'VS']\n",
      "['no key']\n",
      "['no key']\n",
      "['/r', 'Dinner Meetup', 'Thursday', '7:30pm']\n",
      "['February', '3 years']\n",
      "['Christmas']\n",
      "['SLC']\n",
      "['Mia Love', 'Ben McAdams', 'Utah', '4th']\n",
      "['Georgians', 'Salt Lake']\n",
      "['Lee', 'Utah', 'GOP', 'US Supreme Court']\n",
      "['no key']\n",
      "['the Year', '7']\n",
      "['no key']\n",
      "['no key']\n",
      "['KSL']\n",
      "['no key']\n",
      "['two days']\n",
      "['Saturday']\n",
      "['SLC']\n",
      "['no key']\n",
      "['no key']\n",
      "['PSA', 'the South Salt Lake post']\n",
      "['no key']\n",
      "['San Diego', 'Salt Lake City', 'today']\n"
     ]
    }
   ],
   "source": [
    "for city in city_sent:\n",
    "    pprint(city['keys'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
